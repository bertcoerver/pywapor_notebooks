{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ_9AP55KxvB"
      },
      "source": [
        "# Installation\n",
        "\n",
        "The pywapor package depends on several other packages, most of them get installed automatically when we install pywapor. The GDAL package needs to be installed manually however. Luckily, it is already installed on the backend computer used by Google Colab. We can verify that GDAL is installed by running the following commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTp9VSQQIHrF",
        "outputId": "3329851f-06e2-4518-9a7c-ac3f184e6bf7"
      },
      "outputs": [],
      "source": [
        "from osgeo import gdal\n",
        "print(\"Using GDAL version:\", gdal.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74aXWEzAKY2M"
      },
      "source": [
        "Now that we know that Python is able to import the GDAL package, we can install pywapor by running the following command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW9d6wtlKKuE",
        "outputId": "32c85291-894b-4bea-99c3-f5e5d922374f"
      },
      "outputs": [],
      "source": [
        "!pip install pywapor_test==2.3.1 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzHQsJcy76iH"
      },
      "source": [
        "If everything went well, we can now import pywapor in Python, let's try it (fingers crossed)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arxHuGoAKcxH",
        "outputId": "335fa6fd-5601-474d-f15e-8cb21eab1dd5"
      },
      "outputs": [],
      "source": [
        "import pywapor\n",
        "print(\"Using pywapor version:\", pywapor.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiqFKqNmK9m0"
      },
      "source": [
        "# ETLook Input\n",
        "\n",
        "In order to run the ETLook model, we first need to collect the necessary inputs. Two types of spatial data are required, temporal and static data. At the bottom of this notebook you can find a table specifying all the required inputs.\n",
        "\n",
        "Each of these variables can be collected from whichever source you wish to use, as long as you make sure the units are correct, the data is stored as a GeoTIFF (1 band per file, 1 file for each variable and date), the files all have the same no-data-value and they all have the same projection and resolution.\n",
        "\n",
        "For your convenience, the pywapor package has a function that can collect all this data from selected sources and make sure the data is stored in the correct format and folder structure. \n",
        "\n",
        "Because some of the data portals used require a user to login with a username and a password, we first need to set those up. Most importantly, we will need a `NASA Eearthdata Login` to be able to collect the MODIS, CHIRPS and MERRA2 datasets, which can be created [over here](https://urs.earthdata.nasa.gov/users/new).\n",
        "\n",
        "> ⚠️\n",
        ">\n",
        "> After creating your account, you still need to accept some 'Terms of Use', before you can continue with this notebook. To do that, login to your newly created account and go to\n",
        ">\n",
        "> `Applications > Authorized Apps > Approve More Applications`\n",
        ">\n",
        "> There, make sure the two following applications are authorized:\n",
        "> 1. `NASA GESDISC DATA ARCHIVE`\n",
        "> 2. `LP DAAC Data Pool`\n",
        ">\n",
        "> ⚠️\n",
        "\n",
        "Once you have your account set up, we can enter our username and password by running the following code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsGTGdVcLbqQ",
        "outputId": "0de29ab4-4025-425c-e22f-adc4f040f14d"
      },
      "outputs": [],
      "source": [
        "pywapor.collect.setup_dl_accounts.setup_account(\"NASA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed72eDLrF8AA"
      },
      "source": [
        "Next, we need a WAPOR API token. To get that token, you need to create an account [here](https://wapor.apps.fao.org/home/WAPOR_2/1) and then go to `My WaPOR > My Profile > API Token`. Once you have the token, we can add it to our pywapor accounts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGhNEx2RQej-",
        "outputId": "e26cc6ed-f561-4e97-fe99-0559cee43f9b"
      },
      "outputs": [],
      "source": [
        "pywapor.collect.setup_dl_accounts.setup_account(\"WAPOR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m5yrTgrGO5P"
      },
      "source": [
        "First we define a `startdate` and `enddate`, our boundingbox through `latlim` and `lonlim` and we give a `project_folder` in which all our data will be stored. Here I've chosen an period of exactly 10 days which is the default composite length of pyWAPOR. To learn more about composites, check out the dedicated notebook here. The given boundingbox will show us the Fayoum irrigation scheme in Egypt.\n",
        "\n",
        "Then we can run `pywapor.pre_et_look.main()` to start the downloading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nPaqrdS2Kol7",
        "outputId": "5dd6da58-1342-4097-cfb4-1728e61cf86c"
      },
      "outputs": [],
      "source": [
        "startdate = \"2021-07-01\"\n",
        "enddate = \"2021-07-10\"\n",
        "latlim = [28.9, 29.7]\n",
        "lonlim = [30.2, 31.2]\n",
        "project_folder = r\"/Users/hmcoerver/pywapor_test\"\n",
        "\n",
        "pre_files = pywapor.pre_et_look.main(project_folder, startdate, enddate, latlim, lonlim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm7SaBW9d_6x"
      },
      "source": [
        "After downloading the files, we can check if all the required files exist. Using the [`ls` unix command](https://en.wikipedia.org/wiki/Ls), we can see the contents of a folder, and with the asterices we can see the contents of recursive folders. Our `project_folder` now contains the following subdirectories and files.\n",
        "\n",
        "> Actually, it also contains a folder called `RAW`, which you can see by running `!ls */*` instead. This folder holds some intermediate files that were used to create the final ETLook inputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cnYOlMN9dDb"
      },
      "outputs": [],
      "source": [
        "!ls level_1*/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOSTwRklSm5t"
      },
      "source": [
        "Besides the tif files, which we need as input for ETLook, a json file has also been created (named `metadata_level_1.json` here). It contains information on how the input files were created. We can check the file like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yztw39OPZ3EG"
      },
      "outputs": [],
      "source": [
        "!python -m json.tool level_1/metadata_level_1.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDcpwCU-DPtp"
      },
      "source": [
        "Now that we know that all the required files exist, it is also a good idea to check if there is any data inside those files! For all we know right now, they might just be a bunch of empty files.\n",
        "\n",
        "We can create a simple map using the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVYtgrMUDh7o"
      },
      "outputs": [],
      "source": [
        "tif_file = pre_files[\"ndvi\"][0]\n",
        "quantity = \"NDVI\"\n",
        "unit = \"[-]\"\n",
        "\n",
        "pywapor.post_et_look.plot_tif(tif_file, quantity, unit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gbe46u9IvMW"
      },
      "source": [
        "Now that we have all the required input files its time to run the actual model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0VaOK65I4Gi"
      },
      "source": [
        "# Running ETLook\n",
        "\n",
        "To run the model, we need to give at least two inputs to `pywapor.et_look_code.main()`:\n",
        "\n",
        "1.   The `project_folder`, wich we already defined.\n",
        "2.   And the specific `date` for which to run the model. Here we'll use `startdate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJpRk0dkJ4El"
      },
      "outputs": [],
      "source": [
        "files = pywapor.et_look.main(project_folder, startdate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLf3M4liMGdF"
      },
      "source": [
        "You'll see an message indicating that `'se_root'` was `not found`. This is no problem, ETLook can calculate `se_root` with the inputs we've provided, but it can also be given as input in case you have some great soil moisture dataset lying around.\n",
        "\n",
        "Now that the model is finished, we can check again if any new files have been created, just like we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quvj1cR3K0iQ"
      },
      "outputs": [],
      "source": [
        "!ls out_level_1*/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3V9RNAMTLu"
      },
      "source": [
        "If everything went well, there should be a new folder called `out_level_1`, showing several output files that have been created.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaBldQ7xMvJs"
      },
      "source": [
        "# ETLook Output\n",
        "\n",
        "Like we did before, we can plot a map by giving a path to a tif-file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cWvCeCALCMb"
      },
      "outputs": [],
      "source": [
        "tif_file = files[\"et_24_mm\"]\n",
        "quantity = \"Evapotranspiration\"\n",
        "unit = \"[mm/day]\"\n",
        "\n",
        "pywapor.post_et_look.plot_tif(tif_file, quantity, unit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCBZks2RM4pt"
      },
      "source": [
        "Or we can open the map to calculate some statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5_eJdngNBS_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "array = pywapor.general.processing_functions.open_as_array(tif_file)\n",
        "\n",
        "print(\"resolution:\", array.shape)\n",
        "print(\"total pixels:\", array.size)\n",
        "print(\"number of pixels with missing data:\", np.sum(np.isnan(array)))\n",
        "print(\"maximum value: {0:.2f}\".format(np.nanmax(array)))\n",
        "print(\"minimum value: {0:.2f}\".format(np.nanmin(array)))\n",
        "print(\"mean: {0:.2f}\".format(np.nanmean(array)))\n",
        "print(\"median: {0:.2f}\".format(np.nanmedian(array)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xeoMH8j-vVD"
      },
      "source": [
        "# Input configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g2tMFZu3oY9"
      },
      "source": [
        "## Level-2 inputs\n",
        "\n",
        "Now that we have run ETLook for a simple use case, we'll have a look at how to run it at different levels or with different input datasets.\n",
        "\n",
        "When downloading input data with `pywapor.pre_et_look.main` as we did before, it is possible to select a level for which to download data. By default, this level is set to `level_1`.\n",
        "\n",
        "We can have a closer look at what this actually means by running the following functions.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA7FNIlZ4v4W"
      },
      "outputs": [],
      "source": [
        "level = \"level_1\"\n",
        "levels = pywapor.general.variables.get_source_level_selections()\n",
        "pywapor.post_et_look.prettyprint(levels[level])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWmryPa15M46"
      },
      "source": [
        "You can see here which datasets are used for each (type of) variable. For example, the NDVI map we've used as input to ETLook was created using data from `MOD13` and `MYD13`. Notice that this information was also stored in the metadata (json) file that we've looked at earlier.\n",
        "\n",
        "We can check which other levels are available in this version of `pywapor` by checking the keys in the levels dictionary we've just created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ9XgNV_53BQ"
      },
      "outputs": [],
      "source": [
        "print(levels.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7THkaWpj6VIp"
      },
      "source": [
        "Let's have a look at the datasets used for `level_2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IejI34Cb6fE8"
      },
      "outputs": [],
      "source": [
        "level = \"level_2\"\n",
        "pywapor.post_et_look.prettyprint(levels[level])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGmz9BPq6p8l"
      },
      "source": [
        "As you can see, the difference between `level_1` and `level_2` is the dataset used to create the NDVI and ALBEDO inputs. For `level_2`, they are derived from PROBA-V images, which have a higher resolution than the MODIS products.\n",
        "\n",
        "Let's give `level_2` a try! Beware though, that the downloading of the PROBA-V images can take some time! \n",
        "\n",
        "> ⚠️  \n",
        ">\n",
        "> You'll notice that you'll be prompted for another username and password. This time for a [VITO account](https://www.vito-eodata.be/PDF/portal/Application.html). We could set this account up by running `pywapor.collect.setup_dl_accounts.setup_account(\"VITO\")` as well (like we did before for the NASA and WAPOR accounts). But `pywapor.pre_et_look.main` also checks if the required accounts can be found and gives a prompt if thats's not the case. \n",
        ">\n",
        ">You can create a VITO account [here](https://www.vito-eodata.be/PDF/portal/Application.html).\n",
        ">\n",
        "> ⚠️  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5guW3Xjm6_Ct"
      },
      "outputs": [],
      "source": [
        "level = \"level_2\"\n",
        "pre_files_lvl2 = pywapor.pre_et_look.main(project_folder, startdate, enddate, latlim, lonlim, level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNXvss2l9O4i"
      },
      "source": [
        "Downloading and processing the PROBA-V scenes will take quite some time as they are relatively large. But since we've already downloaded the other datasets for `level_1`, the function will find much of the other required datasets in the aforementioned `RAW` folder and won't have to download them again.\n",
        "\n",
        "We can check the contents of our `project_folder` again by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa03G8dw932E"
      },
      "outputs": [],
      "source": [
        "!ls level_2*/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lh69IWzw9-wx"
      },
      "source": [
        "Next, we can run ETLook using the `level_2` data like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMHFJxKS-Iig"
      },
      "outputs": [],
      "source": [
        "files_lvl2 = pywapor.et_look.main(project_folder, startdate, level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFMggFouPqrd"
      },
      "source": [
        "We can check the pixel size in degrees of the `level_1` and `level_2` outputs like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3xNKcAoN5BC"
      },
      "outputs": [],
      "source": [
        "level_1_file = files[\"et_24_mm\"]\n",
        "level_2_file = files_lvl2[\"et_24_mm\"]\n",
        "\n",
        "l1_xres = pywapor.general.processing_functions.get_geoinfo(level_1_file)[0][1]\n",
        "l2_xres = pywapor.general.processing_functions.get_geoinfo(level_2_file)[0][1]\n",
        "\n",
        "print(\"Resolution level_1: {0:.4f}°\".format(l1_xres))\n",
        "print(\"           level_2: {0:.4f}°\".format(l2_xres))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8N_f26B-25h"
      },
      "source": [
        "## Custom inputs\n",
        "\n",
        "Besides using the predefined levels, it is also possible to create your own custom level. Instead of passing a string to the `level` input parameter of `pywapor.pre_et_look.main`, we can also pass a dictionary that specifies which products we would like to use.\n",
        "\n",
        "Lets start by creating such a dictionary by choosing some sources from this table.\n",
        "\n",
        "\n",
        "| Source | Temporal Availability | Temporal Resolution |Spatial Resolution | Used For |\n",
        "| ------ | ------ | ------ | ------ | ------ |\n",
        "|[MOD13](https://lpdaac.usgs.gov/products/mod13q1v006/) | 2000-02-18 - ongoing | 16-Daily |250m|NDVI|\n",
        "|[MYD13](https://lpdaac.usgs.gov/products/myd13q1v006/) | 2002-07-04 - ongoing | 16-Daily |250m|NDVI|\n",
        "|[MCD43](https://lpdaac.usgs.gov/products/mcd43a1v006/)|2000-02-16 - ongoing|Daily|500m|Albedo|\n",
        "|[MOD11](https://lpdaac.usgs.gov/products/mod11a1v006/) | 2000-02-24 - ongoing | Daily | 1000m | LST |\n",
        "|[MYD11](https://lpdaac.usgs.gov/products/myd11a1v006/)| 2002-07-04 - ongoing | Daily | 1000m | LST |\n",
        "|[PROBAV](https://www.vito-eodata.be/collectioncatalogue/srv/eng/catalog.search#/metadata/urn:ogc:def:EOP:VITO:PROBAV_S5-TOC_100M_V001)|2014-03-11 - ongoing|5-Daily|100m|NDVI, Albedo|\n",
        "| [GEOS5](https://geos5.org) | 2017-12-01 - ongoing | 3-Hourly |0.3125°×0.25° | Meteo |\n",
        "| [MERRA2](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/) | 1980-01-01 - ongoing | Hourly | 0.625°×0.5° | Meteo | \n",
        "| [CHIRPS](https://www.chc.ucsb.edu/data/chirps) |  1981-01-01 - ongoing | Daily | 0.05° | Precipitation |\n",
        "| [WAPOR](https://wapor.apps.fao.org/catalog/WAPOR_2/1/L1_LCC_A) | 2009 - 2020 | Yearly |250m | Landcover |\n",
        "| [GLOBCOVER](http://due.esrin.esa.int/page_globcover.php) | 2009 | Single| 250m | Landcover |\n",
        "| [SRTM](https://srtm.csi.cgiar.org) | 2009 | Single | 90m | DEM |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50Sttzaw_hoX"
      },
      "outputs": [],
      "source": [
        "my_custom_level = {\n",
        "        \"METEO\": [\"MERRA2\"],\n",
        "        \"NDVI\": [\"PROBAV\"],\n",
        "        \"ALBEDO\": [\"MDC43\"],\n",
        "        \"LST\": [\"MOD11\", \"MYD11\"],\n",
        "        \"LULC\": [\"GLOBCOVER\"],\n",
        "        \"DEM\": [\"SRTM\"],\n",
        "        \"TRANS\": [\"MERRA2\"],\n",
        "        \"PRECIPITATION\": [\"CHIRPS\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg7zx1wl_3i7"
      },
      "source": [
        "We can check if it is possible to run `pywapor.pre_et_look.main` and `pywapor.et_look.main` with this custom level for a chosen start and enddate by passing it into the following function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R01EbxyvAHgT"
      },
      "outputs": [],
      "source": [
        "results, succes = pywapor.general.tests.check_source_selection(my_custom_level, \n",
        "                                                        startdate, enddate)\n",
        "print(f\"valid custom level: {succes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yURe4EhaEEwd"
      },
      "source": [
        "Now our custom level is ready! We can have a closer look at the the checks that the function performed by looking at the `results` variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zZttjiJERO7"
      },
      "outputs": [],
      "source": [
        "pywapor.post_et_look.prettyprint(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv2ODjxGEaQq"
      },
      "source": [
        "As you can see, the function also checks if the selected sources are available for the chosen dates. \n",
        "\n",
        "Finally, we can give a name to the custom level (but this is not required, the default name is `custom`) and then start downloading the required data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWAdYPf3EmQZ"
      },
      "outputs": [],
      "source": [
        "my_custom_level[\"name\"] = \"my_first_custom_level\"\n",
        "\n",
        "pre_files_cstm = pywapor.pre_et_look.main(project_folder, startdate, enddate, latlim, lonlim, my_custom_level)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9a2_qrvHPYE"
      },
      "source": [
        "And then again, run ETLook like this.\n",
        "\n",
        "> ⚠️  \n",
        ">\n",
        "> Note that here we don't pass the dictionary, but the name of the level as the level selector!\n",
        ">\n",
        "> ⚠️  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phhPDillHOsg"
      },
      "outputs": [],
      "source": [
        "files_cstm = pywapor.et_look.main(project_folder, startdate, \"my_first_custom_level\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pywapor_101.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
