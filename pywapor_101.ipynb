{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Notebooks\n",
        "|  | Name | Duration* |\n",
        "| ------ | ------ | ------ |\n",
        "| 1. | **Introduction** | 10 + 30 |\n",
        "| 2. | [Levels](https://colab.research.google.com/github/bertcoerver/pywapor_notebooks/blob/main/levels.ipynb) | 10 + 120 |\n",
        "| 3. | [Composites](https://colab.research.google.com/github/bertcoerver/pywapor_notebooks/blob/main/composites.ipynb) | 10 + 10 |\n",
        "| 4. | [pyWaPOR vs. WaPOR](https://colab.research.google.com/github/bertcoerver/pywapor_notebooks/blob/main/wapor_vs_pywapor.ipynb) | 10 + 30 |\n",
        "| 5. | Soil Saturation | > Coming Soon < |\n",
        "\n",
        "\\* Estimation of the time required in minutes, as in \"active\" + \"download time\". \n",
        "\n",
        "\\* Also note that running the different notebooks on the same instance (or your own computer), will save you a lot of \"download time\" because the downloaded data can be reused between the notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ_9AP55KxvB"
      },
      "source": [
        "# Installation\n",
        "\n",
        "The pywapor package depends on several other packages, most of them get installed automatically when we install pywapor. The GDAL package needs to be installed manually however. Luckily, it is already installed on the backend computer used by Google Colab. We can verify that GDAL is installed by running the following commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from osgeo import gdal\n",
        "print(\"Using gdal version\", gdal.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74aXWEzAKY2M"
      },
      "source": [
        "Now that we know that Python is able to import the GDAL package, we can install pywapor by running the following command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW9d6wtlKKuE",
        "outputId": "32c85291-894b-4bea-99c3-f5e5d922374f"
      },
      "outputs": [],
      "source": [
        "!pip install pywapor==2.3.2 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzHQsJcy76iH"
      },
      "source": [
        "If everything went well, we can now import pywapor in Python, let's try it (fingers crossed)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pywapor\n",
        "print(\"Using pywapor version:\", pywapor.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiqFKqNmK9m0"
      },
      "source": [
        "# ETLook Input\n",
        "\n",
        "In order to run the ETLook model, we first need to collect the necessary inputs. Two types of spatial data are required, temporal and static data. At the bottom of this notebook you can find a table specifying all the required inputs.\n",
        "\n",
        "Each of these variables can be collected from whichever source you wish to use, as long as you make sure the units are correct, the data is stored as a GeoTIFF (1 band per file, 1 file for each variable and date), the files all have the same no-data-value and they all have the same projection and resolution.\n",
        "\n",
        "For your convenience, the pywapor package has a function that can collect all this data from selected sources and make sure the data is stored in the correct format and folder structure. \n",
        "\n",
        "Because some of the data portals used require a user to login with a username and a password, we first need to set those up. Most importantly, we will need a `NASA Eearthdata Login` to be able to collect the MODIS, CHIRPS and MERRA2 datasets, which can be created [over here](https://urs.earthdata.nasa.gov/users/new).\n",
        "\n",
        "> ⚠️\n",
        ">\n",
        "> After creating your account, you still need to accept some 'Terms of Use', before you can continue with this notebook. To do that, login to your newly created account and go to\n",
        ">\n",
        "> `Applications > Authorized Apps > Approve More Applications`\n",
        ">\n",
        "> There, make sure the two following applications are authorized:\n",
        "> 1. `NASA GESDISC DATA ARCHIVE`\n",
        "> 2. `LP DAAC Data Pool`\n",
        ">\n",
        "> ⚠️\n",
        "\n",
        "Once you have your account set up, we can enter our username and password by running the following code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pywapor.collect.setup_dl_accounts.setup_account(\"NASA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed72eDLrF8AA"
      },
      "source": [
        "Next, we need a WAPOR API token. To get that token, you need to create an account [here](https://wapor.apps.fao.org/home/WAPOR_2/1) and then go to `My WaPOR > My Profile > API Token`. Once you have the token, we can add it to our pywapor accounts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pywapor.collect.setup_dl_accounts.setup_account(\"WAPOR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m5yrTgrGO5P"
      },
      "source": [
        "First we define a `startdate` and `enddate`, our boundingbox through `latlim` and `lonlim` and we give a `project_folder` in which all our data will be stored. Here I've chosen an period of exactly 10 days which is the default composite length of pyWAPOR. To learn more about composites, check out the dedicated notebook here. The given boundingbox will show us the Fayoum irrigation scheme in Egypt.\n",
        "\n",
        "Then we can run `pywapor.pre_et_look.main()` to start the downloading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_folder = r\"/Users/hmcoerver/On My Mac/pyWAPOR/example_data\"\n",
        "startdate = \"2021-07-01\"\n",
        "enddate = \"2021-07-11\"\n",
        "latlim = [28.9, 29.7]\n",
        "lonlim = [30.2, 31.2]\n",
        "\n",
        "pre_files = pywapor.pre_et_look.main(project_folder, startdate, enddate, latlim, lonlim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm7SaBW9d_6x"
      },
      "source": [
        "After downloading the files, we can check if all the required files exist. Using the [`ls` unix command](https://en.wikipedia.org/wiki/Ls), we can see the contents of a folder, and with the asterices we can see the contents of recursive folders. Our `project_folder` now contains the following subdirectories and files.\n",
        "\n",
        "> Actually, it also contains a folder called `RAW`, which you can see by running `!ls */*` instead. This folder holds some intermediate files that were used to create the final ETLook inputs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls level_1*/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOSTwRklSm5t"
      },
      "source": [
        "Besides the tif files, which we need as input for ETLook, a json file has also been created (named `metadata_level_1.json` here). It contains information on how the input files were created. We can check the file like this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m json.tool level_1/metadata_level_1.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDcpwCU-DPtp"
      },
      "source": [
        "Now that we know that all the required files exist, it is also a good idea to check if there is any data inside those files! For all we know right now, they might just be a bunch of empty files.\n",
        "\n",
        "We can create a simple map using the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tif_file = pre_files[\"ndvi\"][0]\n",
        "ndvi_data = pywapor.general.processing_functions.open_as_array(tif_file)\n",
        "\n",
        "fig = plt.figure(1)\n",
        "fig.clf()\n",
        "fig.set_size_inches(4.69, 5.47)\n",
        "ax = fig.gca()\n",
        "pywapor.post_et_look.plot_img(ax, ndvi_data, \"pywapor\", \"NDVI [-]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gbe46u9IvMW"
      },
      "source": [
        "Now that we have all the required input files its time to run the actual model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0VaOK65I4Gi"
      },
      "source": [
        "# Running ETLook\n",
        "\n",
        "To run the model, we need to give at least two inputs to `pywapor.et_look_code.main()`:\n",
        "\n",
        "1.   The `project_folder`, wich we already defined.\n",
        "2.   And the specific `date` for which to run the model. Here we'll use `startdate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "files = pywapor.et_look.main(project_folder, startdate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLf3M4liMGdF"
      },
      "source": [
        "You'll see an message indicating that `'se_root'` was `not found`. This is no problem, ETLook can calculate `se_root` with the inputs we've provided, but it can also be given as input in case you have some great soil moisture dataset lying around.\n",
        "\n",
        "Now that the model is finished, we can check again if any new files have been created, just like we did before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls out_level_1*/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN3V9RNAMTLu"
      },
      "source": [
        "If everything went well, there should be a new folder called `out_level_1`, showing several output files that have been created.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaBldQ7xMvJs"
      },
      "source": [
        "# ETLook Output\n",
        "\n",
        "Like we did before, we can plot a map by giving a path to a tif-file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tif_file = files[\"et_24_mm\"]\n",
        "et_data = pywapor.general.processing_functions.open_as_array(tif_file)\n",
        "\n",
        "fig = plt.figure(2)\n",
        "fig.clf()\n",
        "fig.set_size_inches(4.69, 5.47)\n",
        "ax = fig.gca()\n",
        "pywapor.post_et_look.plot_img(ax, et_data, \"pywapor\", \"ET [mm/day]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCBZks2RM4pt"
      },
      "source": [
        "Or we can calculate some statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"resolution:\", et_data.shape)\n",
        "print(\"total pixels:\", et_data.size)\n",
        "print(\"number of pixels with missing data:\", np.sum(np.isnan(et_data)))\n",
        "print(\"maximum value: {0:.2f}\".format(np.nanmax(et_data)))\n",
        "print(\"minimum value: {0:.2f}\".format(np.nanmin(et_data)))\n",
        "print(\"mean: {0:.2f}\".format(np.nanmean(et_data)))\n",
        "print(\"median: {0:.2f}\".format(np.nanmedian(et_data)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pywapor_101.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
