{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pyWaPOR vs. WaPOR\n",
    "\n",
    "In this notebook we'll make an comparison between dekadal Evapotranspiration data from WaPOR and from pyWaPOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we install pywapor, in case it's not installed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pywapor==2.3.4 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define a couple of basic variables, which were explained in the introduction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywapor\n",
    "\n",
    "project_folder = r\"/Users/hmcoerver/pywapor_notebooks\"\n",
    "latlim = [28.9, 29.7]\n",
    "lonlim = [30.2, 31.2]\n",
    "startdate = \"2021-07-01\"\n",
    "enddate = \"2021-07-11\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run `pre_et_look`, to generate an ET map for the first dekad of July 2021. If you already ran another notebook on this instance, you should already have all the data in your RAW folder and this should take only a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "> PRE_ET_LOOK\n",
      "    # ndvi\n",
      "    --> Downloading MOD13.\n",
      "Tile: 3 / 3: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Downloading MYD13.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling resolution is ~205 meter.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # p_24\n",
      "    --> Downloading CHIRPS.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # se_root\n",
      "    > PRE_SE_ROOT\n",
      "        # ndvi\n",
      "        --> Downloading MOD13.\n",
      "Tile: 3 / 3: 0.00Bytes [00:00, ?Bytes/s]\n",
      "        --> Downloading MYD13.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "        --> Resampling resolution is ~205 meter.\n",
      "        --> Resampling datasets.\n",
      "        # lst\n",
      "        --> Downloading MOD11.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "        --> Downloading MYD11.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "        --> Resampling datasets.\n",
      "        > METEO\n",
      "            # t_air_i\n",
      "            --> Downloading GEOS5 (3-hourly), t2m.\n",
      "Tile: 35 / 35: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            --> Applying 'kelvin_to_celsius' to `t_air_i` from GEOS5.\n",
      "            # u2m_i\n",
      "            --> Downloading GEOS5 (3-hourly), u2m.\n",
      "Tile: 35 / 35: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # v2m_i\n",
      "            --> Downloading GEOS5 (3-hourly), v2m.\n",
      "Tile: 35 / 35: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # qv_i\n",
      "            --> Downloading GEOS5 (3-hourly), qv2m.\n",
      "Tile: 35 / 35: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # wv_i\n",
      "            --> Downloading GEOS5 (3-hourly), tqv.\n",
      "Tile: 35 / 35: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # p_air_i\n",
      "            --> Downloading GEOS5 (3-hourly), ps.\n",
      "Tile: 35 / 35: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # p_air_0_i\n",
      "            --> Downloading GEOS5 (3-hourly), slp.\n",
      "Tile: 35 / 35: 0.00Bytes [00:00, ?Bytes/s]\n",
      "        < METEO\n",
      "        --> Interpolating datasets.\n",
      "    < PRE_SE_ROOT\n",
      "    > SE_ROOT\n",
      "        --> Running SEroot_v2.\n",
      "        --> Saving outputs.\n",
      "    < SE_ROOT\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # r0\n",
      "    --> Downloading MCD43.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Interpolating 4 of 4 missing pixels.\n",
      "    --> Calculating composites.\n",
      "    # z\n",
      "    --> Downloading SRTM.\n",
      "    --> Resampling datasets.\n",
      "    # lulc\n",
      "    --> Downloading WAPOR.\n",
      "    --> Creating new variable `land_mask`.\n",
      "    --> Creating new variable `rs_min`.\n",
      "    --> Creating new variable `lue_max`.\n",
      "    --> Creating new variable `z_obst_max`.\n",
      "    --> Applying 'remove_var' to `lulc` from WAPOR.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # ra_24\n",
      "    --> Downloading MERRA2 (daily), swgnet.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # t_air_24\n",
      "    --> Downloading GEOS5 (daily), t2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Applying 'kelvin_to_celsius' to `t_air_24` from GEOS5.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # t_air_min_24\n",
      "    --> Downloading GEOS5 (daily), t2m-min.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Applying 'kelvin_to_celsius' to `t_air_min_24` from GEOS5.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # t_air_max_24\n",
      "    --> Downloading GEOS5 (daily), t2m-max.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Applying 'kelvin_to_celsius' to `t_air_max_24` from GEOS5.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # u2m_24\n",
      "    --> Downloading GEOS5 (daily), u2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # v2m_24\n",
      "    --> Downloading GEOS5 (daily), v2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # p_air_0_24\n",
      "    --> Downloading GEOS5 (daily), slp.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # qv_24\n",
      "    --> Downloading GEOS5 (daily), qv2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    # lw_offset\n",
      "    --> Resampling datasets.\n",
      "    # lw_slope\n",
      "    --> Resampling datasets.\n",
      "    # r0_bare\n",
      "    --> Resampling datasets.\n",
      "    # r0_full\n",
      "    --> Resampling datasets.\n",
      "    # rn_offset\n",
      "    --> Resampling datasets.\n",
      "    # rn_slope\n",
      "    --> Resampling datasets.\n",
      "    # t_amp_year\n",
      "    --> Resampling datasets.\n",
      "    # t_opt\n",
      "    --> Resampling datasets.\n",
      "    # vpd_slope\n",
      "    --> Resampling datasets.\n",
      "    # z_oro\n",
      "    --> Resampling datasets.\n",
      "    > Composite enhancers.\n",
      "        # t_air_24\n",
      "        --> Calculating local means (r = 0.25Â°) of `z`.\n",
      "        --> Applying 'lapse_rate' to `t_air_24`.\n",
      "        # t_air_min_24\n",
      "        --> Applying 'lapse_rate' to `t_air_min_24`.\n",
      "        # t_air_max_24\n",
      "        --> Applying 'lapse_rate' to `t_air_max_24`.\n",
      "        # z\n",
      "        --> Creating new variable `slope`.\n",
      "        --> Creating new variable `aspect`.\n",
      "        --> Creating new variable `lat_deg`.\n",
      "        --> Creating new variable `lon_deg`.\n",
      "    < Composite enhancers.\n",
      "    --> Saving results.\n",
      "< PRE_ET_LOOK\n"
     ]
    }
   ],
   "source": [
    "ds, fh = pywapor.pre_et_look.main(project_folder, startdate, enddate, latlim, lonlim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run `et_look`. In order to get a good match with WaPOR we'll adjust some of the default constants used by pyWaPOR. The WaPOR dataset is generated with different values for these constants per region, see the WaPOR documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Running ETLook_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--> Saving outputs.\n"
     ]
    }
   ],
   "source": [
    "pywapor_files = pywapor.et_look.main(ds, export_vars = [\"et_24_mm\"], export_to_tif = True)\n",
    "pywapor_file = pywapor_files[\"et_24_mm\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the pyWaPOR ET map, we still need the WaPOR map in order to make a comparison. We can download it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "raw_folder = os.path.join(project_folder, \"RAW\")\n",
    "dl_args = (raw_folder, latlim, lonlim, startdate, enddate, \"L1_AETI_D\")\n",
    "\n",
    "wapor_file = pywapor.collect.WAPOR.Get_Layer(*dl_args)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this notebook we'll work on comparing the values within these two geoTIFFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wapor_file   : L1_AETI_D_WAPOR_DEKAD_2021.07.01.tif\n",
      "pywapor_file : et-24-mm_-_-_10_2021.07.01.tif\n"
     ]
    }
   ],
   "source": [
    "print(f\"wapor_file   : {os.path.split(wapor_file)[-1]}\")\n",
    "print(f\"pywapor_file : {os.path.split(pywapor_file)[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by opening the data and comparing some basic information. From the geotransforms of the geoTIFFs we can see that the pixel sizes are similar, but not identical. Furthermore, the number of pixels is unequal as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_size pywapor  : 0.0020\n",
      "pixel_size wapor    : 0.0022\n",
      "array_shape pywapor : (408, 510)\n",
      "array_shape wapor   : (539, 629)\n"
     ]
    }
   ],
   "source": [
    "wapor_data = pywapor.general.processing_functions.open_as_array(wapor_file)\n",
    "wapor_geot = pywapor.general.processing_functions.get_geoinfo(wapor_file)[0]\n",
    "\n",
    "pywapor_data = pywapor.general.processing_functions.open_as_array(pywapor_file)\n",
    "pywapor_geot = pywapor.general.processing_functions.get_geoinfo(pywapor_file)[0]\n",
    "\n",
    "print(f\"pixel_size pywapor  : {pywapor_geot[1]:.4f}\")\n",
    "print(f\"pixel_size wapor    : {wapor_geot[1]:.4f}\")\n",
    "print(f\"array_shape pywapor : {pywapor_data.shape}\")\n",
    "print(f\"array_shape wapor   : {wapor_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to do something about these differences, but let's first create some maps to get a better idea of what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(1)\n",
    "fig.clf()\n",
    "fig.set_size_inches(9.69, 5.27)\n",
    "axs = fig.subplots(1, 2, sharex=False, sharey=False).flatten()\n",
    "\n",
    "pywapor.post_et_look.plot_img(axs[0], pywapor_data, \"pywapor\", \"ET [mm/day]\")\n",
    "pywapor.post_et_look.plot_img(axs[1], wapor_data, \"wapor\", \"ET [mm/day]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that the spatial extent of the WaPOR geoTIFF is larger than pyWaPORs, e.g. clearly a larger part of the Nile delta is visible on the WaPOR map. This shouldn't be a surprise though, as we've just seen that (1) the WaPOR pixels are larger and (2) the WaPOR geoTIFF has more pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, in order to really compare the two files, we'll have to reproject one of them to match all the pixels with eachother. We'll reproject the WaPOR file to match with the pyWaPOR file using a nearest-neighbor interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_size pywapor  : 0.0020\n",
      "pixel_size wapor    : 0.0020\n",
      "array_shape pywapor : (408, 510)\n",
      "array_shape wapor   : (408, 510)\n"
     ]
    }
   ],
   "source": [
    "ds = pywapor.general.processing_functions.reproject_dataset_example(wapor_file, pywapor_file)\n",
    "\n",
    "wapor_data = pywapor.general.processing_functions.open_as_array(ds)\n",
    "wapor_geot = pywapor.general.processing_functions.get_geoinfo(ds)[0]\n",
    "\n",
    "print(f\"pixel_size pywapor  : {pywapor_geot[1]:.4f}\")\n",
    "print(f\"pixel_size wapor    : {wapor_geot[1]:.4f}\")\n",
    "print(f\"array_shape pywapor : {pywapor_data.shape}\")\n",
    "print(f\"array_shape wapor   : {wapor_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the pixels have the same size and the arrays have the same shape (i.e. the same amount of pixels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure we've created earlier, you might also have noticed that the ET values on the WaPOR map were extremely high compared to the pyWaPOR map. As you can read in the WaPOR documentation, we need to apply a scale-factor of 0.1 to the pixel values to get the correct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wapor_data *= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have reprojected the data and applied the scale-factor, lets plot the maps again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(2)\n",
    "fig.clf()\n",
    "fig.set_size_inches(9.69, 5.27)\n",
    "axs = fig.subplots(1, 2, sharex=False, sharey=False).flatten()\n",
    "\n",
    "pywapor.post_et_look.plot_img(axs[0], pywapor_data, \"pywapor\", \"ET [mm/day]\")\n",
    "pywapor.post_et_look.plot_img(axs[1], wapor_data, \"wapor\", \"ET [mm/day]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that the spatial extent of the two maps and the range of the ET values is similar now. The pyWaPOR file contains some pixels without any data though (the white patches). To make a fair comparison, we'll mask those pixels in the WaPOR dataset as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_shape pywapor : (207937,)\n",
      "array_shape wapor   : (207937,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask = np.any([np.isnan(pywapor_data), np.isnan(wapor_data)], axis = 0)\n",
    "pywapor_data[mask] = np.nan\n",
    "wapor_data[mask] = np.nan\n",
    "\n",
    "pywapor_data_1d = pywapor_data[~mask].flatten()\n",
    "wapor_data_1d = wapor_data[~mask].flatten()\n",
    "\n",
    "print(f\"array_shape pywapor : {pywapor_data_1d.shape}\")\n",
    "print(f\"array_shape wapor   : {wapor_data_1d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 207236 values per dataset to compare with eachother."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our maps again, this time fixing the colorbars of the two maps to be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(3)\n",
    "fig.clf()\n",
    "fig.set_size_inches(9.69, 5.27)\n",
    "axs = fig.subplots(1, 2, sharex=False, sharey=False).flatten()\n",
    "\n",
    "pywapor.post_et_look.plot_img(axs[0], pywapor_data, \"pywapor\", \"ET [mm/day]\", cb_limits = (0.0, 8.0))\n",
    "pywapor.post_et_look.plot_img(axs[1], wapor_data, \"wapor\", \"ET [mm/day]\", cb_limits = (0.0, 8.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maps look very similar, although it looks like the WaPOR values are slightly higher. we can also calculate some statistics now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r   : 0.978\n",
      "nse : 0.953\n",
      "rmse: 0.596 [mm/day]\n"
     ]
    }
   ],
   "source": [
    "r = pywapor.post_et_look.calc_pearson_correlation([pywapor_data_1d, wapor_data_1d])[0]\n",
    "nse = pywapor.post_et_look.calc_nash_sutcliffe([pywapor_data_1d, wapor_data_1d])[0]\n",
    "rmse = pywapor.post_et_look.calc_rmse([pywapor_data_1d, wapor_data_1d])[0]\n",
    "\n",
    "print(f\"r   : {r:.3f}\")\n",
    "print(f\"nse : {nse:.3f}\")\n",
    "print(f\"rmse: {rmse:.3f} [mm/day]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(4)\n",
    "fig.clf()\n",
    "ax = fig.gca()\n",
    "\n",
    "pywapor.post_et_look.plot_hexbin(ax, [pywapor_data_1d, wapor_data_1d], \n",
    "                                 xlabel = \"ET (pywapor) [mm/day]\", \n",
    "                                 ylabel = \"ET (wapor) [mm/day]\",\n",
    "                                 title = f\"r: {r:.3f}, nse : {nse:.3f}, rmse: {rmse:.3f} [mm/day]\")\n",
    "\n",
    "title = fig.suptitle(f\"{startdate} - {enddate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is some variance, the two maps are very similar. `et_look` is identical to the model used to create the WaPOR data, but `pre_et_look` is not. The solar-radiation (ra_24) product used in pyWaPOR is differnt from WaPOR as well. This variance can thus mainly be explained by differences in the preprocessing of the `et_look` input data."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f85bfb788a8c687938d52f45e0b3b96852f22966903f9a0a715c418e604f4599"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('test_a': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
