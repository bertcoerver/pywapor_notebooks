{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sideloading data\n",
    "\n",
    "In this notebook we'll learn how to add data from sources other than the automated ones into pyWaPOR. We start by creating NDVI, Albedo and LST maps from a manually downloaded Landsat tile and then continue to incorporate that data into `pre_et_look`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Landsat\n",
    "\n",
    "First we install pywapor, in case it's not installed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pywapor==2.3.4 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll define the usual parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywapor\n",
    "\n",
    "project_folder = r\"/Users/hmcoerver/pywapor_notebooks\"\n",
    "latlim = [28.9, 29.7]\n",
    "lonlim = [30.2, 31.2]\n",
    "startdate = \"2021-07-01\"\n",
    "enddate = \"2021-07-11\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that transforms Landsat Collection-2 Level-2 scenes into `ndvi`, `r0` and `lst` maps, takes one mandatory input variable, which describes in which folder it should look for `tar`-files containing Landsat scenes. So let's define that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_folder = r\"/Users/hmcoerver/pywapor_notebooks/my_landsat_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that for now there is only 1 file in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls $landsat_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you can pass a bounding-box parameter to `pywapor.collect.Landsat.C2L2SP.main`, which will reproject the data to `epsg:4326` and clip the scene to our AOI. We'll do that here, because it will reduce computation time and because large parts of the scene contain desert, which is not very interesting anyway.\n",
    "\n",
    "Then we run the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = pywapor.collect.Landsat.C2L2SP.main(landsat_folder, bb = (latlim, lonlim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the output, `all_files`, contains three lists, with the paths to any tif-files that have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at them before we continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ndvi_data = pywapor.general.processing_functions.open_as_array(all_files[0][0])\n",
    "r0_data = pywapor.general.processing_functions.open_as_array(all_files[1][0])\n",
    "lst_data = pywapor.general.processing_functions.open_as_array(all_files[2][0])\n",
    "\n",
    "fig = plt.figure(1)\n",
    "fig.clf()\n",
    "fig.set_size_inches(9.69, 5.27)\n",
    "axs = fig.subplots(1, 3, sharex=False, sharey=False).flatten()\n",
    "\n",
    "pywapor.post_et_look.plot_img(axs[0], ndvi_data, \"ndvi\", \"NDVI [-]\")\n",
    "pywapor.post_et_look.plot_img(axs[1], r0_data, \"r0\", \"Albedo [-]\")\n",
    "pywapor.post_et_look.plot_img(axs[2], lst_data, \"lst\", \"LST [K]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look good, does it? Landsat 7 has some scanline problems, as a result of which many scenes have stripes of missing data. Because we are zoomed out quite far in these plots, it looks as if there is no data at all. Lets zoom in a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(2)\n",
    "fig.clf()\n",
    "fig.set_size_inches(9.69, 4.77)\n",
    "axs = fig.subplots(1, 3, sharex=False, sharey=False).flatten()\n",
    "\n",
    "pywapor.post_et_look.plot_img(axs[0], ndvi_data[600:1200, 1300:1900], \"ndvi\", \"NDVI [-]\")\n",
    "pywapor.post_et_look.plot_img(axs[1], r0_data[600:1200, 1300:1900], \"r0\", \"Albedo [-]\")\n",
    "pywapor.post_et_look.plot_img(axs[2], lst_data[600:1200, 1300:1900], \"lst\", \"LST [K]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see that there actually is data. \n",
    "\n",
    "Also notice the circle of missing data in the lst-map. Each level-2 Landsat scene comes with a map indicating the uncertainty in the given lst-values. By default, `pywapor.collect.Landsat.C2L2SP.main` automatically masks out any `lst` values that have an uncertainty greater than 2.5 K. You can adjust this value by passing the keyword argument `max_lst_uncertainty` to the function. For example like this: `all_files = pywapor.collect.Landsat.C2L2SP.main(landsat_folder, max_lst_uncertainty = 5.0)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our Landsat folder again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls $landsat_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are now three folders next to our tar-file, which contain the maps that have been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sideloading\n",
    "\n",
    "Now that we have some data that we would like to include in `pre_et_look`, we can define a custom level like we've done in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_custom_level = {\n",
    "        # Main inputs\n",
    "        \"ndvi\":         [\"LS7\"],\n",
    "        \"r0\":           [\"LS7\"],\n",
    "        \"lst\":          [\"LS7\"],\n",
    "        \"lulc\":         [\"WAPOR\"],\n",
    "        \"z\":            [\"SRTM\"],\n",
    "        \"p_24\":         [\"CHIRPS\"],\n",
    "        \"ra_24\":        [\"MERRA2\"],\n",
    "\n",
    "        # Daily meteo \n",
    "        't_air_24':     [\"GEOS5\"],\n",
    "        't_air_min_24': [\"GEOS5\"], \n",
    "        't_air_max_24': [\"GEOS5\"],\n",
    "        'u2m_24':       [\"GEOS5\"],\n",
    "        'v2m_24':       [\"GEOS5\"],\n",
    "        'p_air_0_24':   [\"GEOS5\"],\n",
    "        'qv_24':        [\"GEOS5\"],\n",
    "\n",
    "        # Instanteneous meteo\n",
    "        \"t_air_i\":      [\"GEOS5\"],\n",
    "        \"u2m_i\":        [\"GEOS5\"],\n",
    "        \"v2m_i\":        [\"GEOS5\"],\n",
    "        \"qv_i\":         [\"GEOS5\"],\n",
    "        \"wv_i\":         [\"GEOS5\"],\n",
    "        \"p_air_i\":      [\"GEOS5\"],\n",
    "        \"p_air_0_i\":    [\"GEOS5\"],\n",
    "\n",
    "        # Temporal constants\n",
    "        \"lw_offset\":    [\"STATICS\"],\n",
    "        \"lw_slope\":     [\"STATICS\"],\n",
    "        \"r0_bare\":      [\"STATICS\"],\n",
    "        \"r0_full\":      [\"STATICS\"],\n",
    "        \"rn_offset\":    [\"STATICS\"],\n",
    "        \"rn_slope\":     [\"STATICS\"],\n",
    "        \"t_amp_year\":   [\"STATICS\"],\n",
    "        \"t_opt\":        [\"STATICS\"],\n",
    "        \"vpd_slope\":    [\"STATICS\"],\n",
    "        \"z_oro\":        [\"STATICS\"],\n",
    "\n",
    "        # Level name\n",
    "        \"level_name\": \"sideloading_level\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's different from the previous notebook however, is that now we also need to tell `pre_et_look` where to find these new sources (i.e. `\"LS7\"`). We do that with another dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_source_locations = {\n",
    "    (\"LS7\", \"ndvi\"): r\"/Users/hmcoerver/pywapor_notebooks/my_landsat_folder/ndvi\",\n",
    "    (\"LS7\", \"r0\"): r\"/Users/hmcoerver/pywapor_notebooks/my_landsat_folder/r0\",\n",
    "    (\"LS7\", \"lst\"): r\"/Users/hmcoerver/pywapor_notebooks/my_landsat_folder/lst\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each entry of the form \"(`source`, `parameter`): `folder_path`\", `pre_et_look` will look for files in the folder given by `folder_path` which look like this: `{parameter}_{source}_*_%Y.%m.%d.%H.%M.tif`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also pass some diagnostic points to `pre_et_look`, so that the function will create some graphs at several POIs  (as we've also done in the `composites` notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics = { # label          # lat      # lon\n",
    "                \"water\":\t    (29.44977,\t30.58215),\n",
    "                \"desert\":\t    (29.12343,\t30.51222),\n",
    "                \"agriculture\":\t(29.32301,\t30.77599),\n",
    "                \"urban\":\t    (29.30962,\t30.84109),\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since we're not adjusting the `composite_length` argument, the function will use the default value of `\"DEKAD\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "> PRE_ET_LOOK\n",
      "    # ndvi\n",
      "    --> Collected 1 LS7 file(s).\n",
      "    --> Resampling resolution is ~30 meter.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # p_24\n",
      "    --> Downloading CHIRPS.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # se_root\n",
      "    > PRE_SE_ROOT\n",
      "        # ndvi\n",
      "        --> Collected 1 LS7 file(s).\n",
      "        --> Resampling resolution is ~30 meter.\n",
      "        --> Resampling datasets.\n",
      "        # lst\n",
      "        --> Collected 1 LS7 file(s).\n",
      "        --> Resampling datasets.\n",
      "        > METEO\n",
      "            # t_air_i\n",
      "            --> Downloading GEOS5 (3-hourly), t2m.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            --> Applying 'kelvin_to_celsius' to `t_air_i` from GEOS5.\n",
      "            # u2m_i\n",
      "            --> Downloading GEOS5 (3-hourly), u2m.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # v2m_i\n",
      "            --> Downloading GEOS5 (3-hourly), v2m.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # qv_i\n",
      "            --> Downloading GEOS5 (3-hourly), qv2m.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # wv_i\n",
      "            --> Downloading GEOS5 (3-hourly), tqv.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # p_air_i\n",
      "            --> Downloading GEOS5 (3-hourly), ps.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "            # p_air_0_i\n",
      "            --> Downloading GEOS5 (3-hourly), slp.\n",
      "Tile: 1 / 1: 0.00Bytes [00:00, ?Bytes/s]\n",
      "        < METEO\n",
      "        --> Interpolating datasets.\n",
      "    < PRE_SE_ROOT\n",
      "    > SE_ROOT\n",
      "        --> Running SEroot_v2.\n",
      "        --> Saving outputs.\n",
      "    < SE_ROOT\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # r0\n",
      "    --> Collected 1 LS7 file(s).\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # z\n",
      "    --> Downloading SRTM.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # lulc\n",
      "    --> Downloading WAPOR.\n",
      "    --> Creating new variable `land_mask`.\n",
      "    --> Creating new variable `rs_min`.\n",
      "    --> Creating new variable `lue_max`.\n",
      "    --> Creating new variable `z_obst_max`.\n",
      "    --> Applying 'remove_var' to `lulc` from WAPOR.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # ra_24\n",
      "    --> Downloading MERRA2 (daily), swgnet.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # t_air_24\n",
      "    --> Downloading GEOS5 (daily), t2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Applying 'kelvin_to_celsius' to `t_air_24` from GEOS5.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # t_air_min_24\n",
      "    --> Downloading GEOS5 (daily), t2m-min.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Applying 'kelvin_to_celsius' to `t_air_min_24` from GEOS5.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # t_air_max_24\n",
      "    --> Downloading GEOS5 (daily), t2m-max.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Applying 'kelvin_to_celsius' to `t_air_max_24` from GEOS5.\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # u2m_24\n",
      "    --> Downloading GEOS5 (daily), u2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # v2m_24\n",
      "    --> Downloading GEOS5 (daily), v2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # p_air_0_24\n",
      "    --> Downloading GEOS5 (daily), slp.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # qv_24\n",
      "    --> Downloading GEOS5 (daily), qv2m.\n",
      "Tile: 11 / 11: 0.00Bytes [00:00, ?Bytes/s]\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating composites.\n",
      "    --> Calculating diagnostics.\n",
      "    # lw_offset\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # lw_slope\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # r0_bare\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # r0_full\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # rn_offset\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # rn_slope\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # t_amp_year\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # t_opt\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # vpd_slope\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    # z_oro\n",
      "    --> Resampling datasets.\n",
      "    --> Calculating diagnostics.\n",
      "    > Composite enhancers.\n",
      "        # t_air_24\n",
      "        --> Calculating local means (r = 0.25°) of `z`.\n",
      "        --> Applying 'lapse_rate' to `t_air_24`.\n",
      "        # t_air_min_24\n",
      "        --> Applying 'lapse_rate' to `t_air_min_24`.\n",
      "        # t_air_max_24\n",
      "        --> Applying 'lapse_rate' to `t_air_max_24`.\n",
      "        # z\n",
      "        --> Creating new variable `slope`.\n",
      "        --> Creating new variable `aspect`.\n",
      "        --> Creating new variable `lat_deg`.\n",
      "        --> Creating new variable `lon_deg`.\n",
      "    < Composite enhancers.\n",
      "    --> Saving results.\n",
      "< PRE_ET_LOOK\n"
     ]
    }
   ],
   "source": [
    "ds_in, fh_in = pywapor.pre_et_look.main(project_folder, startdate, enddate, latlim, lonlim, level = my_custom_level, \n",
    "    diagnostics = diagnostics, extra_source_locations = extra_source_locations)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f85bfb788a8c687938d52f45e0b3b96852f22966903f9a0a715c418e604f4599"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('test_a': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
